{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from matplotlib import rcParams\n",
    "from astropy.wcs import WCS \n",
    "from pathlib import Path\n",
    "from reproject import reproject_interp\n",
    "import sep\n",
    "#import fitsio\n",
    "import photutils\n",
    "from photutils.aperture import CircularAperture, EllipticalAperture, ApertureStats\n",
    "from photutils.aperture import aperture_photometry\n",
    "rcParams['figure.figsize'] = [12., 12.]\n",
    "from scipy.spatial import cKDTree\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://docs.astropy.org/en/stable/io/fits/index.html\n",
    "# https://stackoverflow.com/questions/21583647/reading-headers-from-multiple-fits-file-from-the-same-directory\n",
    "import warnings\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)\n",
    "\n",
    "\n",
    "\n",
    "directory = Path(r\"C:\\Users\\FN-2187\\StarClusters\\Nickel_fits_April13_2023\")\n",
    "\n",
    "fits_files = [f for f in directory.iterdir() if f.suffix.lower() == '.fits']\n",
    "image_data = []\n",
    "image_headers = []\n",
    "records = []\n",
    "\n",
    "for f in fits_files:\n",
    "    with fits.open(f) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "        wcs = WCS(header)\n",
    "        image_data.append(data)\n",
    "        image_headers.append(header)\n",
    "        records.append((f, data, header, wcs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/21583647/reading-headers-from-multiple-fits-file-from-the-same-directory\n",
    "#https://www.w3schools.com/python/ref_string_startswith.asp\n",
    "\n",
    "bias = [\n",
    "    data for f, data in zip(fits_files, image_data)\n",
    "    if f.stem.startswith('d') and 100 <= int(f.stem.split('d')[-1]) <= 109\n",
    "]\n",
    "\n",
    "domeflatB = [\n",
    "    data for f, data in zip(fits_files, image_data)\n",
    "    if f.stem.startswith('d') and 110 <= int(f.stem.split('d')[-1]) <= 114\n",
    "]\n",
    "\n",
    "domeflatV = [\n",
    "    data for f, data in zip(fits_files, image_data)\n",
    "    if f.stem.startswith('d') and 115 <= int(f.stem.split('d')[-1]) <= 119\n",
    "]\n",
    "\n",
    "domeflatR = [\n",
    "    data for f, data in zip(fits_files, image_data)\n",
    "    if f.stem.startswith('d') and 120 <= int(f.stem.split('d')[-1]) <= 124\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawB = [\n",
    "    data for f, data in zip(fits_files, image_data)\n",
    "    if f.stem.startswith('d') and 156 <= int(f.stem.split('d')[-1]) <= 160\n",
    "]\n",
    "rawV = [\n",
    "    data for f, data in zip(fits_files, image_data)\n",
    "    if f.stem.startswith('d') and 161 <= int(f.stem.split('d')[-1]) <= 165\n",
    "]\n",
    "rawR = [\n",
    "    data for f, data in zip(fits_files, image_data)\n",
    "    if f.stem.startswith('d') and 166 <= int(f.stem.split('d')[-1]) <= 170  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#data type dictates where the party goes\n",
    "print(type(rawB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_bias=np.median(np.stack(bias),axis=0)\n",
    "\n",
    "def domecal(filt, bias):\n",
    "    clean = [flat - bias for flat in filt] \n",
    "    master_dome= np.mean(clean, axis=0)\n",
    "    return master_dome/np.mean(master_dome)\n",
    "\n",
    "def scical(sci, flat):\n",
    "    cleaned_images = []\n",
    "    for image in sci:\n",
    "        # Subtract bias\n",
    "        corrected = image - master_bias\n",
    "\n",
    "        # Divide by normalized flat\n",
    "        cleaned = corrected / flat\n",
    "\n",
    "        cleaned_images.append(cleaned)\n",
    "    \n",
    "    return cleaned_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normdomB=domecal(domeflatB,master_bias)\n",
    "normdomV=domecal(domeflatV,master_bias)\n",
    "normdomR=domecal(domeflatR,master_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FN-2187\\AppData\\Local\\Temp\\ipykernel_11236\\2972619361.py:15: RuntimeWarning: divide by zero encountered in divide\n",
      "  cleaned = corrected / flat\n",
      "C:\\Users\\FN-2187\\AppData\\Local\\Temp\\ipykernel_11236\\2972619361.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  cleaned = corrected / flat\n"
     ]
    }
   ],
   "source": [
    "cleaned_sci_imagesB= scical(rawB, normdomB)\n",
    "cleaned_sci_imagesV= scical(rawV, normdomV)\n",
    "cleaned_sci_imagesR= scical(rawR, normdomR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibB = [data for f, data in zip(fits_files, image_data) if 126 <= int(f.stem.split('d')[-1]) <= 130]\n",
    "calibV = [data for f, data in zip(fits_files, image_data) if 131 <= int(f.stem.split('d')[-1]) <= 135]\n",
    "calibR = [data for f, data in zip(fits_files, image_data) if 136 <= int(f.stem.split('d')[-1]) <= 140]\n",
    "\n",
    "calibB_headers = [header for f, header in zip(fits_files, image_headers) if 126 <= int(f.stem.split('d')[-1]) <= 130]\n",
    "calibV_headers = [header for f, header in zip(fits_files, image_headers) if 131 <= int(f.stem.split('d')[-1]) <= 135]\n",
    "calibR_headers = [header for f, header in zip(fits_files, image_headers) if 136 <= int(f.stem.split('d')[-1]) <= 140]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FN-2187\\AppData\\Local\\Temp\\ipykernel_11236\\2972619361.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  cleaned = corrected / flat\n",
      "C:\\Users\\FN-2187\\AppData\\Local\\Temp\\ipykernel_11236\\2972619361.py:15: RuntimeWarning: divide by zero encountered in divide\n",
      "  cleaned = corrected / flat\n"
     ]
    }
   ],
   "source": [
    "cleaned_standardB= scical(calibB,normdomB)\n",
    "cleaned_standardR= scical(calibR,normdomR)\n",
    "cleaned_standardV= scical(calibV,normdomV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Clean science frames with only bias correction\n",
    "# def scical_bias_only(sci, master_bias):\n",
    "#     cleaned_images = []\n",
    "#     for image in sci:\n",
    "#         corrected = (image - master_bias).astype(np.float32)\n",
    "#         cleaned_images.append(corrected)\n",
    "#     return cleaned_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_sci_imagesB = bias_only_scical(rawB, normdomB)\n",
    "# cleaned_sci_imagesV = bias_only_scical(rawV, normdomV)\n",
    "# cleaned_sci_imagesR = bias_only_scical(rawR, normdomR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_images = {\n",
    "    'B': cleaned_sci_imagesB,\n",
    "    'V': cleaned_sci_imagesV,\n",
    "    'R': cleaned_sci_imagesR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_headers = [\n",
    "    header for f, header in zip(fits_files, image_headers)\n",
    "    if f.stem.startswith('d') and 100 <= int(f.stem.split('d')[-1]) <= 109\n",
    "]\n",
    "domeflatB_header  = [\n",
    "    header for f, header in zip(fits_files, image_headers)\n",
    "    if f.stem.startswith('d') and 110 <= int(f.stem.split('d')[-1]) <= 114\n",
    "]\n",
    "domeflatV_header  = [\n",
    "    header for f, header in zip(fits_files, image_headers)\n",
    "    if f.stem.startswith('d') and 115 <= int(f.stem.split('d')[-1]) <= 119\n",
    "]\n",
    "domeflatR_header  = [\n",
    "    header for f, header in zip(fits_files, image_headers)\n",
    "    if f.stem.startswith('d') and 120 <= int(f.stem.split('d')[-1]) <= 124\n",
    "]\n",
    "rawB_header = [\n",
    "    header for f, header in zip(fits_files, image_headers)\n",
    "    if f.stem.startswith('d') and 156 <= int(f.stem.split('d')[-1]) <= 160\n",
    "]\n",
    "rawV_header  = [\n",
    "    header for f, header in zip(fits_files, image_headers)\n",
    "    if f.stem.startswith('d') and 161 <= int(f.stem.split('d')[-1]) <= 165\n",
    "]\n",
    "rawR_header  = [\n",
    "    header for f, header in zip(fits_files, image_headers)\n",
    "    if f.stem.startswith('d') and 166 <= int(f.stem.split('d')[-1]) <= 170\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(image_headers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_wcs = WCS(rawB_header[0]) # or rawB_header[0]\n",
    "\n",
    "def align_stack(cleaned_images, headers):\n",
    "    aligned = []\n",
    "    for img, hdr in zip(cleaned_images, headers):\n",
    "        array, _ = reproject_interp((img, WCS(hdr)), ref_wcs)\n",
    "        aligned.append(array)\n",
    "    return np.median(np.stack(aligned), axis=0)\n",
    "\n",
    "stacked_B = align_stack(cleaned_sci_imagesB, rawB_header)\n",
    "stacked_V = align_stack(cleaned_sci_imagesV, rawV_header)\n",
    "stacked_R = align_stack(cleaned_sci_imagesR, rawR_header)\n",
    "\n",
    "# no header attached\n",
    "stacked_calibB = np.median(np.stack(cleaned_standardB), axis=0)\n",
    "stacked_calibV = np.median(np.stack(cleaned_standardB), axis=0)\n",
    "stacked_calibR = np.median(np.stack(cleaned_standardB), axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photometry(data, thresh=3.5, minarea=3, use_elliptical=True, flux_percentile_cut=None):\n",
    "    import numpy as np\n",
    "    import sep\n",
    "    from astropy.table import Table\n",
    "    from photutils.aperture import CircularAperture, ApertureStats\n",
    "\n",
    "    # Ensure proper dtype and byte order\n",
    "    data = np.nan_to_num(data.astype(np.float32))\n",
    "    if data.dtype.byteorder not in ('=', '|'):\n",
    "        data = data.astype(data.dtype.newbyteorder('='))\n",
    "\n",
    "    # Background subtraction\n",
    "    bkg = sep.Background(data)\n",
    "    data_sub = data - bkg.back()\n",
    "\n",
    "    # Source extraction\n",
    "    objects = sep.extract(data_sub, thresh=thresh, minarea=minarea)\n",
    "    if len(objects) == 0:\n",
    "        raise ValueError(\"No sources found in image.\")\n",
    "\n",
    "    if use_elliptical:\n",
    "        # Build a mask of valid parameters before unpacking\n",
    "        ny, nx = data.shape\n",
    "        valid_mask = (\n",
    "            (objects['a'] > 0.5) & (objects['b'] > 0.5) &\n",
    "            (objects['a'] < 100) & (objects['b'] < 100) &\n",
    "            (objects['x'] - objects['a'] * 2 > 0) & (objects['x'] + objects['a'] * 2 < nx) &\n",
    "            (objects['y'] - objects['b'] * 2 > 0) & (objects['y'] + objects['b'] * 2 < ny) &\n",
    "            np.isfinite(objects['x']) & np.isfinite(objects['y']) &\n",
    "            np.isfinite(objects['a']) & np.isfinite(objects['b']) & np.isfinite(objects['theta'])\n",
    "        )\n",
    "\n",
    "        # Filter objects\n",
    "        filtered = objects[valid_mask]\n",
    "\n",
    "        if len(filtered) == 0:\n",
    "            raise ValueError(\"No valid sources remaining after filtering.\")\n",
    "\n",
    "        x = filtered['x']\n",
    "        y = filtered['y']\n",
    "        a = filtered['a'] * 2.0\n",
    "        b = filtered['b'] * 2.0\n",
    "        theta = filtered['theta']\n",
    "\n",
    "        try:\n",
    "            fluxes, flux_errs, _ = sep.sum_ellipse(\n",
    "                data_sub, x, y, a, b, theta,\n",
    "                err=bkg.globalrms, subpix=1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"⚠️ Still failing after filtering:\")\n",
    "            for i in range(min(5, len(x))):\n",
    "                print(f\"x={x[i]:.2f}, y={y[i]:.2f}, a={a[i]:.2f}, b={b[i]:.2f}, θ={theta[i]:.2f}\")\n",
    "            raise e\n",
    "\n",
    "        if flux_percentile_cut is not None:\n",
    "            threshold = np.nanpercentile(fluxes, flux_percentile_cut)\n",
    "            keep = fluxes > threshold\n",
    "            x = x[keep]\n",
    "            y = y[keep]\n",
    "            fluxes = fluxes[keep]\n",
    "            flux_errs = flux_errs[keep]\n",
    "\n",
    "        phot_table = Table()\n",
    "        phot_table['xcenter'] = x\n",
    "        phot_table['ycenter'] = y\n",
    "        phot_table['aperture_sum'] = fluxes\n",
    "        phot_table['flux_err'] = flux_errs\n",
    "\n",
    "    else:\n",
    "        # Circular fallback\n",
    "        x = objects['x']\n",
    "        y = objects['y']\n",
    "        positions = np.column_stack((x, y))\n",
    "        apertures = CircularAperture(positions, r=3.0)\n",
    "        stats = [ApertureStats(data_sub, ap) for ap in apertures]\n",
    "        fluxes = [s.sum for s in stats]\n",
    "        flux_errs = [s.sum_err for s in stats]\n",
    "\n",
    "        phot_table = Table()\n",
    "        phot_table['xcenter'] = x\n",
    "        phot_table['ycenter'] = y\n",
    "        phot_table['aperture_sum'] = fluxes\n",
    "        phot_table['flux_err'] = flux_errs\n",
    "\n",
    "    return phot_table, objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_tableB, objectsB= photometry(stacked_B, use_elliptical=True)\n",
    "phot_tableV, objectsV= photometry(stacked_V, use_elliptical=True)\n",
    "phot_tableR, objectsR= photometry(stacked_R, use_elliptical=True)\n",
    "\n",
    "standard_tableB, standard_objB= photometry(stacked_calibB, use_elliptical=True)\n",
    "standard_tableV, standard_objV= photometry(stacked_calibV, use_elliptical=True)\n",
    "standard_tableR, standard_objR= photometry(stacked_calibR, use_elliptical=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n",
      "     flux_err     \n",
      "------------------\n",
      "11.800341934163756\n",
      " 12.43865256025139\n",
      "16.218018737654187\n",
      "11.800341934163756\n",
      "11.125469069289561\n",
      "     flux_err     \n",
      "------------------\n",
      "11.800341934163756\n",
      " 12.43865256025139\n",
      "16.218018737654187\n",
      "11.800341934163756\n",
      "11.125469069289561\n",
      "15.234175930189748\n",
      " 18.44950325976899\n",
      "11.800341934163756\n",
      "10.406923381108074\n",
      "10.406923381108074\n"
     ]
    }
   ],
   "source": [
    "print(len(phot_tableB))\n",
    "print(phot_tableB['flux_err'][:5])  # should be real values\n",
    "# bkg = sep.Background(stacked_B)\n",
    "# data_sub = stacked_B - bkg.back()\n",
    "print(phot_tableB['flux_err'][:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zeropoint(standard_flux, known_mag, exposure):\n",
    "    \"\"\"\n",
    "    Calculate photometric zeropoint.\n",
    "    standard_flux: Measured flux from standard star\n",
    "    known_mag: Catalog magnitude of the standard star (e.g., Johnson B, V, R)\n",
    "    \"\"\"\n",
    "    flux_per_sec = standard_flux / exposure\n",
    "    return known_mag + 2.5 * np.log10(flux_per_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_fluxB= standard_tableB['aperture_sum'][0]  # assuming one star is detected\n",
    "std_fluxV= standard_tableV['aperture_sum'][0] \n",
    "std_fluxR= standard_tableR['aperture_sum'][0] \n",
    "\n",
    "# Example: known magnitude of standard star in V band\n",
    "known_mag_B = 13.056\n",
    "known_mag_V = 13.327\n",
    "known_mag_R = 13.456\n",
    "\n",
    "zp_B = compute_zeropoint(std_fluxB, known_mag_B,80)\n",
    "zp_V = compute_zeropoint(std_fluxV, known_mag_V,80)\n",
    "zp_R = compute_zeropoint(std_fluxR, known_mag_R,120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xcenter', 'ycenter', 'aperture_sum', 'flux_err']\n"
     ]
    }
   ],
   "source": [
    "print(standard_tableB.colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_to_mag(flux, zp):\n",
    "    \"\"\"\n",
    "    Convert background-subtracted flux to magnitude using zeropoint.\n",
    "    \"\"\"\n",
    "    return -2.5 * np.log10(flux) + zp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phot_tableB['mag'] = flux_to_mag(phot_tableB['aperture_sum'], zp_B)\n",
    "# phot_tableV['mag'] = flux_to_mag(phot_tableV['aperture_sum'], zp_V)\n",
    "# phot_tableR['mag'] = flux_to_mag(phot_tableR['aperture_sum'], zp_R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.cKDTree.html\n",
    "# https://youtu.be/Glp7THUpGow?si=NfE2DVtA2xL9I-CA\n",
    "# Extract coordinates from photometry tables\n",
    "coords_B = np.column_stack((phot_tableB['xcenter'], phot_tableB['ycenter']))\n",
    "coords_V = np.column_stack((phot_tableV['xcenter'], phot_tableV['ycenter']))\n",
    "coords_R = np.column_stack((phot_tableR['xcenter'], phot_tableR['ycenter']))\n",
    "\n",
    "# Build KD-trees\n",
    "tree_V = cKDTree(coords_V)\n",
    "tree_R = cKDTree(coords_R)\n",
    "\n",
    "# Match B to V and B to R\n",
    "max_sep = 3.0  # pixel distance tolerance for matching\n",
    "\n",
    "dist_BV, idx_BV = tree_V.query(coords_B, distance_upper_bound=max_sep)\n",
    "dist_BR, idx_BR = tree_R.query(coords_B, distance_upper_bound=max_sep)\n",
    "\n",
    "# Only keep good matches (where distance is below threshold)\n",
    "valid_BV = dist_BV < max_sep\n",
    "valid_BR = dist_BR < max_sep\n",
    "valid_all = valid_BV & valid_BR\n",
    "\n",
    "# Final matched indices\n",
    "idx_B = np.where(valid_all)[0]\n",
    "idx_V = idx_BV[valid_all]\n",
    "idx_R = idx_BR[valid_all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matched_B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmatched_B\u001b[49m\u001b[38;5;241m.\u001b[39mcolnames)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(matched_V\u001b[38;5;241m.\u001b[39mcolnames)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(matched_R\u001b[38;5;241m.\u001b[39mcolnames)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matched_B' is not defined"
     ]
    }
   ],
   "source": [
    "print(matched_B.colnames)\n",
    "print(matched_V.colnames)\n",
    "print(matched_R.colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_B = phot_tableB[idx_B]\n",
    "matched_V = phot_tableV[idx_V]\n",
    "matched_R = phot_tableR[idx_R]\n",
    "\n",
    "combined_catalog = pd.DataFrame({\n",
    "    'x': matched_B['xcenter'],\n",
    "    'y': matched_B['ycenter'],\n",
    "    'flux_B': matched_B['aperture_sum'],\n",
    "    'flux_V': matched_V['aperture_sum'],\n",
    "    'flux_R': matched_R['aperture_sum'],\n",
    "    \n",
    "    # ADD THESE:\n",
    "    'flux_err_B': matched_B['flux_err'],\n",
    "    'flux_err_V': matched_V['flux_err'],\n",
    "    'flux_err_R': matched_R['flux_err']\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_catalog['flux_err_B'] = matched_B['flux_err'].data\n",
    "combined_catalog['flux_err_V'] = matched_V['flux_err'].data\n",
    "combined_catalog['flux_err_R'] = matched_R['flux_err'].data\n",
    "\n",
    "\n",
    "\n",
    "print(matched_B['flux_err'][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_catalog[['flux_B', 'flux_err_B']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_B['flux_err'][:10])\n",
    "print(type(matched_B['flux_err']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exposure times (in seconds)\n",
    "exp_B = 120\n",
    "exp_V = 120\n",
    "exp_R = 60\n",
    "\n",
    "valid_flux_mask = (\n",
    "    (combined_catalog['flux_B'] > 0) &\n",
    "    (combined_catalog['flux_V'] > 0) &\n",
    "    (combined_catalog['flux_R'] > 0)\n",
    ")\n",
    "clean_catalog = combined_catalog[valid_flux_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_catalog.columns)\n",
    "print(len(combined_catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_catalog['flux_B'] /= exp_B\n",
    "clean_catalog['flux_V'] /= exp_V\n",
    "clean_catalog['flux_R'] /= exp_R\n",
    "\n",
    "clean_catalog['flux_err_B'] /= exp_B\n",
    "clean_catalog['flux_err_V'] /= exp_V\n",
    "clean_catalog['flux_err_R'] /= exp_R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_to_mag_err(flux, flux_err):\n",
    "    return 1.0857 * (flux_err / flux)\n",
    "\n",
    "# Compute magnitude errors\n",
    "clean_catalog['mag_err_B'] = flux_to_mag_err(clean_catalog['flux_B'], clean_catalog['flux_err_B'])\n",
    "clean_catalog['mag_err_V'] = flux_to_mag_err(clean_catalog['flux_V'], clean_catalog['flux_err_V'])\n",
    "clean_catalog['mag_err_R'] = flux_to_mag_err(clean_catalog['flux_R'], clean_catalog['flux_err_R'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR for each band\n",
    "clean_catalog['snr_B'] = clean_catalog['flux_B'] / clean_catalog['flux_err_B']\n",
    "clean_catalog['snr_V'] = clean_catalog['flux_V'] / clean_catalog['flux_err_V']\n",
    "clean_catalog['snr_R'] = clean_catalog['flux_R'] / clean_catalog['flux_err_R']\n",
    "\n",
    "# Filter on SNR *before* computing magnitudes\n",
    "clean_catalog = clean_catalog[\n",
    "    (clean_catalog['snr_B'] > 3) &\n",
    "    (clean_catalog['snr_V'] > 3) &\n",
    "    (clean_catalog['snr_R'] > 3)\n",
    "]\n",
    "print(len(clean_catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_catalog['mag_B'] = flux_to_mag(clean_catalog['flux_B'], zp_B)\n",
    "clean_catalog['mag_V'] = flux_to_mag(clean_catalog['flux_V'], zp_V)\n",
    "clean_catalog['mag_R'] = flux_to_mag(clean_catalog['flux_R'], zp_R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_catalog[['flux_err_B', 'flux_err_V', 'flux_err_R']].describe())\n",
    "print((combined_catalog['flux_B'] <= 0).sum(), \"B band <= 0\")\n",
    "print((combined_catalog['flux_V'] <= 0).sum(), \"V band <= 0\")\n",
    "print((combined_catalog['flux_R'] <= 0).sum(), \"R band <= 0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial matched sources:\", len(combined_catalog))\n",
    "print(\"After valid flux filter:\", len(clean_catalog))\n",
    "\n",
    "clean_catalog['snr_B'] = clean_catalog['flux_B'] / clean_catalog['flux_err_B']\n",
    "clean_catalog['snr_V'] = clean_catalog['flux_V'] / clean_catalog['flux_err_V']\n",
    "clean_catalog['snr_R'] = clean_catalog['flux_R'] / clean_catalog['flux_err_R']\n",
    "\n",
    "clean_catalog = clean_catalog[\n",
    "    (clean_catalog['snr_B'] > 5) &\n",
    "    (clean_catalog['snr_V'] > 5) &\n",
    "    (clean_catalog['snr_R'] > 5)\n",
    "]\n",
    "\n",
    "\n",
    "print(\"SNR > 3 in all bands:\", len(clean_catalog))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Apply extinction correction ---\n",
    "k_B, k_V, k_R = 0.25, 0.15, 0.10\n",
    "A_V = 0.20\n",
    "A_B = 1.32 * A_V\n",
    "A_R = 0.81 * A_V\n",
    "\n",
    "X_B = np.mean([hdr['AIRMASS'] for hdr in rawB_header])\n",
    "X_V = np.mean([hdr['AIRMASS'] for hdr in rawV_header])\n",
    "X_R = np.mean([hdr['AIRMASS'] for hdr in rawR_header])\n",
    "\n",
    "m_atm_ext_B = k_B * X_B\n",
    "m_atm_ext_V = k_V * X_V\n",
    "m_atm_ext_R = k_R * X_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_catalog['mag_B_corr'] = clean_catalog['mag_B'] - m_atm_ext_B - A_B\n",
    "clean_catalog['mag_V_corr'] = clean_catalog['mag_V'] - m_atm_ext_V - A_V\n",
    "clean_catalog['mag_R_corr'] = clean_catalog['mag_R'] - m_atm_ext_R - A_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_catalog['B-V_corr'] = clean_catalog['mag_B_corr'] - clean_catalog['mag_V_corr']\n",
    "clean_catalog['V-R_corr'] = clean_catalog['mag_V_corr'] - clean_catalog['mag_R_corr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_catalog['B-V_corr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_catalog['B-V_err'] = np.sqrt(clean_catalog['mag_err_B']**2 + clean_catalog['mag_err_V']**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(\n",
    "    clean_catalog['B-V_corr'],\n",
    "    clean_catalog['mag_V_corr'],\n",
    "    xerr=clean_catalog['B-V_err'],\n",
    "    fmt='o', color='black', ms=3, elinewidth=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(clean_catalog['B-V_corr'], clean_catalog['mag_V_corr'], s=10, c='k')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Corrected B − V')\n",
    "plt.ylabel('Corrected V Magnitude')\n",
    "plt.title('Extinction-Corrected CMD')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clean_catalog['B-V_corr'], bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gzip\n",
    "\n",
    "isochrone_file = 'isoc_z019.dat.gz'\n",
    "\n",
    "# Read gzipped isochrone file\n",
    "with gzip.open(isochrone_file, 'rt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract only the rows containing actual data (skip headers)\n",
    "data_lines = [line for line in lines if not line.startswith('#') and len(line.strip().split()) > 5]\n",
    "\n",
    "# Convert to DataFrame\n",
    "columns = ['Z', 'logAge', 'Mini', 'Mass', 'Teff', 'logL', 'logg', 'Mbol', 'UBmag', 'Bmag', 'Vmag', 'Rmag', 'Imag', 'Jmag', 'Hmag', 'Kmag']\n",
    "iso_data = pd.DataFrame([list(map(float, line.strip().split())) for line in data_lines], columns=columns)\n",
    "print(\"Available log(Age) range:\", iso_data['logAge'].min(), \"to\", iso_data['logAge'].max())\n",
    "print(\"Sample rows:\\n\", iso_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "E_BV = 0.0155\n",
    "A_V = 3.1 * E_BV  # Extinction in V band\n",
    "distance_modulus = 15.5  # Provided earlier\n",
    "\n",
    "# Optional: extinction in B band (roughly A_B ≈ 4.1 * E(B-V) for Johnson filters)\n",
    "A_B = 4.1 * E_BV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_age_target = 7.499\n",
    "iso_subset = iso_data[np.isclose(iso_data['logAge'], log_age_target, atol=0.01)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected color and magnitude\n",
    "iso_subset['B-V_corr'] = iso_subset['Bmag'] - iso_subset['Vmag'] - E_BV\n",
    "iso_subset['V_corr'] = iso_subset['Vmag'] + distance_modulus + A_V\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.scatter(clean_catalog['B-V_corr'], clean_catalog['mag_V_corr'], s=10, color='black', label='Cluster stars')\n",
    "plt.plot(iso_subset['B-V_corr'], iso_subset['V_corr'], color='red', linewidth=2, label=f\"Isochrone logAge={log_age_target}\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('B − V (mag)')\n",
    "plt.ylabel('V (mag)')\n",
    "plt.title('CMD with Corrected Isochrone')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('CMD with Isochrone.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_modulus = 15.48\n",
    "\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.scatter(clean_catalog['B-V_corr'], clean_catalog['mag_V_corr'], s=10, color='black', label='Cluster stars')\n",
    "\n",
    "# Overlay isochrones\n",
    "for log_age in [7.4, 7.5, 7.5991]:\n",
    "    iso_subset = iso_data[np.isclose(iso_data['logAge'], log_age, atol=0.01)]\n",
    "    iso_subset = iso_subset.drop_duplicates(subset=['Bmag', 'Vmag']).sort_values('Vmag')\n",
    "\n",
    "    # Correct the isochrone magnitudes and colors\n",
    "    iso_BV = iso_subset['Bmag'] - iso_subset['Vmag'] - E_BV\n",
    "    iso_V = iso_subset['Vmag'] + distance_modulus\n",
    "\n",
    "    plt.plot(iso_BV, iso_V, lw=1.5, label=f'Isochrone logAge={log_age}')\n",
    "\n",
    "# Finalize plot\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('B − V (mag)')\n",
    "plt.ylabel('V (mag)')\n",
    "plt.title('CMD with Corrected Isochrones')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('CMD_with_Isochrones.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_data.to_csv(\"iso_data_subset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
